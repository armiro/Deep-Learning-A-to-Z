{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_notebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armiro/Deep-Learning-A-to-Z/blob/master/Convolutional_Neural_Networks/cnn_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pTsP5hS1Fm7o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 0 - Mounting Drive into the CoLab's working directory"
      ]
    },
    {
      "metadata": {
        "id": "5BDPrKUgF3yL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This needs to be run just at the first time to bring all Google Drive files\n",
        "# into an accessible path (after mounting, go to the \"files\" tab on the left \n",
        "# and right-click on your file or folder and click on \"copy path\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9wumUZSP-ePZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 1 - Building the CNN"
      ]
    },
    {
      "metadata": {
        "id": "qsDlliX-90Qg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers.advanced_activations import LeakyReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "20NLlC9V-qcA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "classifier.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), \n",
        "                      input_shape=(64, 64, 3), activation='relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2), strides=None))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# devising two pooling layers beside each other, accuracy has been increased to some extent\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units=128, activation='relu'))\n",
        "classifier.add(Dense(units=64, activation='relu'))\n",
        "classifier.add(Dense(units=32, activation='relu'))\n",
        "# classifier.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "# using 'LeakyReLU' did not end in a significant change\n",
        "\n",
        "classifier.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# changing activation function to 'tanh' had worse result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IvPFZkrF_HXt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compiling the CNN\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', \n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "# using predefined 'SGD' had worse result, while 'adamax' had the same result \n",
        "# as 'adam'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ufvGYVvK_LsH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 2 - Fitting the CNN to the images"
      ]
    },
    {
      "metadata": {
        "id": "wcG4CPm3_K6y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GG3b31g-_SE4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, \n",
        "                                   zoom_range=0.2, horizontal_flip=True,\n",
        "                                   rotation_range=45)\n",
        "\n",
        "# adding rotation_range resulted in a few increase, whereas adding \n",
        "# 'vertical_flip' had worsen the result\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M9L1HfNRDDAG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run to see where is the current working directory (cwd) and what are the\n",
        "# folders/files available under this directory (optional)\n",
        "\n",
        "import os\n",
        "cwd = os.getcwd()\n",
        "files = os.listdir(cwd)\n",
        "print(files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BYZ7OnNn_VIA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# change the directory address according to your Drive path\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('./drive/My Drive/dataset/training_set',\n",
        "                                                 target_size=(64, 64),\n",
        "                                                 batch_size=16,\n",
        "                                                 class_mode='binary')\n",
        "\n",
        "# increasing 'batch_size' slows down the system, however a slight increase is observed\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('./drive/My Drive/dataset/test_set',\n",
        "                                            target_size=(64, 64),\n",
        "                                            batch_size=16,\n",
        "                                            class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9X68VQpN_aMo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch=8000,\n",
        "                         epochs=25,\n",
        "                         validation_data=test_set,\n",
        "                         validation_steps=2000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tSp2sCfS_c7x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 3 - Saving the model as an HDF5 file"
      ]
    },
    {
      "metadata": {
        "id": "-3yfM08f_tgb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier.save('trained_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}